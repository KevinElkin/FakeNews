{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px\n",
    "import datetime\n",
    "from matplotlib.pyplot import *\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec \n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import utils\n",
    "import multiprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "import torch\n",
    "import transformers as ppb # pytorch transformers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from etl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Post Author</th>\n",
       "      <th>Link</th>\n",
       "      <th>Label</th>\n",
       "      <th>Year</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14052</th>\n",
       "      <td>foreign company united state significantly hi...</td>\n",
       "      <td>Sherrod Brown</td>\n",
       "      <td>April 25, 2011</td>\n",
       "      <td>Tom Feran</td>\n",
       "      <td>https://www.politifact.com/factchecks/2011/apr...</td>\n",
       "      <td>true</td>\n",
       "      <td>2011</td>\n",
       "      <td>[foreign, company, united, state, significantl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15255</th>\n",
       "      <td>john boehner called repealing rest stimulus w...</td>\n",
       "      <td>Austan Goolsbee</td>\n",
       "      <td>September 13, 2010</td>\n",
       "      <td>Robert Farley</td>\n",
       "      <td>https://www.politifact.com/factchecks/2010/sep...</td>\n",
       "      <td>false</td>\n",
       "      <td>2010</td>\n",
       "      <td>[john, boehner, called, repealing, rest, stimu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>american want traditional marriage defined de...</td>\n",
       "      <td>Bill Johnson</td>\n",
       "      <td>July 10, 2013</td>\n",
       "      <td>Stephen Koff</td>\n",
       "      <td>https://www.politifact.com/factchecks/2013/jul...</td>\n",
       "      <td>false</td>\n",
       "      <td>2013</td>\n",
       "      <td>[american, want, traditional, marriage, define...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13182</th>\n",
       "      <td>stimulus created zero job</td>\n",
       "      <td>National Republican Senatorial Committee</td>\n",
       "      <td>October 21, 2011</td>\n",
       "      <td>Warren Fiske</td>\n",
       "      <td>https://www.politifact.com/factchecks/2011/oct...</td>\n",
       "      <td>false</td>\n",
       "      <td>2011</td>\n",
       "      <td>[stimulus, created, zero, job]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9657</th>\n",
       "      <td>history united state 168 presidential nominee...</td>\n",
       "      <td>Harry Reid</td>\n",
       "      <td>November 22, 2013</td>\n",
       "      <td>Louis Jacobson</td>\n",
       "      <td>https://www.politifact.com/factchecks/2013/nov...</td>\n",
       "      <td>true</td>\n",
       "      <td>2013</td>\n",
       "      <td>[history, united, state, 168, presidential, no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Quote  \\\n",
       "14052   foreign company united state significantly hi...   \n",
       "15255   john boehner called repealing rest stimulus w...   \n",
       "10204   american want traditional marriage defined de...   \n",
       "13182                          stimulus created zero job   \n",
       "9657    history united state 168 presidential nominee...   \n",
       "\n",
       "                                         Source                Date  \\\n",
       "14052                             Sherrod Brown      April 25, 2011   \n",
       "15255                           Austan Goolsbee  September 13, 2010   \n",
       "10204                              Bill Johnson       July 10, 2013   \n",
       "13182  National Republican Senatorial Committee    October 21, 2011   \n",
       "9657                                 Harry Reid   November 22, 2013   \n",
       "\n",
       "           Post Author                                               Link  \\\n",
       "14052       Tom Feran   https://www.politifact.com/factchecks/2011/apr...   \n",
       "15255   Robert Farley   https://www.politifact.com/factchecks/2010/sep...   \n",
       "10204    Stephen Koff   https://www.politifact.com/factchecks/2013/jul...   \n",
       "13182    Warren Fiske   https://www.politifact.com/factchecks/2011/oct...   \n",
       "9657   Louis Jacobson   https://www.politifact.com/factchecks/2013/nov...   \n",
       "\n",
       "       Label  Year                                             Tokens  \n",
       "14052   true  2011  [foreign, company, united, state, significantl...  \n",
       "15255  false  2010  [john, boehner, called, repealing, rest, stimu...  \n",
       "10204  false  2013  [american, want, traditional, marriage, define...  \n",
       "13182  false  2011                     [stimulus, created, zero, job]  \n",
       "9657    true  2013  [history, united, state, 168, presidential, no...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = format_data('politifact_data.csv')\n",
    "df['Tokens'] = df['Quote'].apply(lambda x: nltk.word_tokenize(x))\n",
    "# df = df[~df.Label.str.contains(\"remove\")]\n",
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Post Author</th>\n",
       "      <th>Link</th>\n",
       "      <th>Year</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>false</th>\n",
       "      <td>8508</td>\n",
       "      <td>8508</td>\n",
       "      <td>8508</td>\n",
       "      <td>8508</td>\n",
       "      <td>8508</td>\n",
       "      <td>8508</td>\n",
       "      <td>8508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>8201</td>\n",
       "      <td>8201</td>\n",
       "      <td>8201</td>\n",
       "      <td>8201</td>\n",
       "      <td>8201</td>\n",
       "      <td>8201</td>\n",
       "      <td>8201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Quote  Source  Date  Post Author  Link  Year  Tokens\n",
       "Label                                                      \n",
       "false   8508    8508  8508         8508  8508  8508    8508\n",
       "true    8201    8201  8201         8201  8201  8201    8201"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Post Author</th>\n",
       "      <th>Link</th>\n",
       "      <th>Label</th>\n",
       "      <th>Year</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12426</th>\n",
       "      <td>say traffic fatality fallen dramatically even...</td>\n",
       "      <td>Sam Adams</td>\n",
       "      <td>March 9, 2012</td>\n",
       "      <td>Ian K. Kullgren</td>\n",
       "      <td>https://www.politifact.com/factchecks/2012/mar...</td>\n",
       "      <td>true</td>\n",
       "      <td>2012</td>\n",
       "      <td>[say, traffic, fatality, fallen, dramatically,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9490</th>\n",
       "      <td>job involve minimum wage overwhelmingly job y...</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>January 13, 2014</td>\n",
       "      <td>Dave Umhoefer</td>\n",
       "      <td>https://www.politifact.com/factchecks/2014/jan...</td>\n",
       "      <td>false</td>\n",
       "      <td>2014</td>\n",
       "      <td>[job, involve, minimum, wage, overwhelmingly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11838</th>\n",
       "      <td>oregon school receive million dollar per year...</td>\n",
       "      <td>Ron Wyden</td>\n",
       "      <td>June 29, 2012</td>\n",
       "      <td>Charles Pope</td>\n",
       "      <td>https://www.politifact.com/factchecks/2012/jun...</td>\n",
       "      <td>true</td>\n",
       "      <td>2012</td>\n",
       "      <td>[oregon, school, receive, million, dollar, per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15229</th>\n",
       "      <td>harry reid voted give special tax break illeg...</td>\n",
       "      <td>Sharron Angle</td>\n",
       "      <td>September 17, 2010</td>\n",
       "      <td>Louis Jacobson</td>\n",
       "      <td>https://www.politifact.com/factchecks/2010/sep...</td>\n",
       "      <td>false</td>\n",
       "      <td>2010</td>\n",
       "      <td>[harry, reid, voted, give, special, tax, break...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>canadian face major donut shortage first day ...</td>\n",
       "      <td>worldnewsdailyreport.com</td>\n",
       "      <td>October 25, 2018</td>\n",
       "      <td>Kyra Haas</td>\n",
       "      <td>https://www.politifact.com/factchecks/2018/oct...</td>\n",
       "      <td>false</td>\n",
       "      <td>2018</td>\n",
       "      <td>[canadian, face, major, donut, shortage, first...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Quote  \\\n",
       "12426   say traffic fatality fallen dramatically even...   \n",
       "9490    job involve minimum wage overwhelmingly job y...   \n",
       "11838   oregon school receive million dollar per year...   \n",
       "15229   harry reid voted give special tax break illeg...   \n",
       "2797    canadian face major donut shortage first day ...   \n",
       "\n",
       "                         Source                Date       Post Author  \\\n",
       "12426                 Sam Adams       March 9, 2012  Ian K. Kullgren    \n",
       "9490               Scott Walker    January 13, 2014    Dave Umhoefer    \n",
       "11838                 Ron Wyden       June 29, 2012     Charles Pope    \n",
       "15229             Sharron Angle  September 17, 2010   Louis Jacobson    \n",
       "2797   worldnewsdailyreport.com    October 25, 2018        Kyra Haas    \n",
       "\n",
       "                                                    Link  Label  Year  \\\n",
       "12426  https://www.politifact.com/factchecks/2012/mar...   true  2012   \n",
       "9490   https://www.politifact.com/factchecks/2014/jan...  false  2014   \n",
       "11838  https://www.politifact.com/factchecks/2012/jun...   true  2012   \n",
       "15229  https://www.politifact.com/factchecks/2010/sep...  false  2010   \n",
       "2797   https://www.politifact.com/factchecks/2018/oct...  false  2018   \n",
       "\n",
       "                                                  Tokens  \n",
       "12426  [say, traffic, fatality, fallen, dramatically,...  \n",
       "9490   [job, involve, minimum, wage, overwhelmingly, ...  \n",
       "11838  [oregon, school, receive, million, dollar, per...  \n",
       "15229  [harry, reid, voted, give, special, tax, break...  \n",
       "2797   [canadian, face, major, donut, shortage, first...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[-int(len(df)*.8):]\n",
    "df_test = df[int(len(df)*.8):]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = df_train.apply(lambda r: TaggedDocument(words=r['Tokens'], tags=r['Label']), axis=1)\n",
    "test_tagged = df_test.apply(lambda r: TaggedDocument(words=r['Tokens'], tags=r['Label']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13367/13367 [00:00<00:00, 2277224.27it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13367/13367 [00:00<00:00, 1216377.28it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1370219.26it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1260233.36it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 2654102.52it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 2704025.35it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 2805086.38it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 2556089.25it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 2792511.91it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1550263.00it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1462508.45it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1506199.43it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1505916.24it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1519260.27it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1445055.46it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1516383.89it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1482070.94it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1559187.43it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1531001.14it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1144679.59it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1099318.85it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1126668.17it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 774874.39it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1162287.49it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1108469.16it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1140557.85it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1097597.13it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1034605.31it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 845132.75it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1172422.87it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1137572.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.5927588270496709\n",
      "Testing F1 score: 0.5926118400926518\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13367/13367 [00:00<00:00, 1223117.53it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13367/13367 [00:00<00:00, 1025896.83it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1162407.98it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1136972.72it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1129664.75it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1155770.30it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1103104.02it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1252099.55it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1155508.28it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 2169624.30it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1513927.08it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1117216.22it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1151899.69it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1143628.87it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1147514.46it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1152799.72it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1550691.79it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1561793.46it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1550305.87it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1537466.72it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1138265.39it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 2843354.38it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1244263.33it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1259582.16it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1423735.03it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 2832580.28it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1470024.43it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1166228.35it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1153606.21it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1140047.61it/s]\n",
      "100%|██████████| 13367/13367 [00:00<00:00, 1485920.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dmm.alpha -= 0.002\n",
    "    model_dmm.min_alpha = model_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.7187312986235787\n",
      "Testing F1 score: 0.7187104430979424\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['false', 'true']\n",
    "cf_matrix = confusion_matrix(y_test, y_pred, labels)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "\n",
    "b, t = plt.ylim() \n",
    "b += 0.5 \n",
    "t -= 0.5 \n",
    "plt.ylim(b, t) \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Post Author</th>\n",
       "      <th>Link</th>\n",
       "      <th>Year</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>false</th>\n",
       "      <td>1720</td>\n",
       "      <td>1720</td>\n",
       "      <td>1720</td>\n",
       "      <td>1720</td>\n",
       "      <td>1720</td>\n",
       "      <td>1720</td>\n",
       "      <td>1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>1622</td>\n",
       "      <td>1622</td>\n",
       "      <td>1622</td>\n",
       "      <td>1622</td>\n",
       "      <td>1622</td>\n",
       "      <td>1622</td>\n",
       "      <td>1622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Quote  Source  Date  Post Author  Link  Year  Tokens\n",
       "Label                                                      \n",
       "false   1720    1720  1720         1720  1720  1720    1720\n",
       "true    1622    1622  1622         1622  1622  1622    1622"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby('Label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6d2bc67fc031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create CBOW model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model2 = gensim.models.Doc2Vec(df_train['Tokens'], min_count = 1, size = 300, \n\u001b[1;32m      5\u001b[0m                                              window = 5, sg = 1) \n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, corpus_file, dm_mean, dm, dbow_words, dm_concat, dm_tag_count, docvecs, docvecs_mapfile, comment, trim_rule, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can't pass a generator as the documents argument. Try a sequence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             self.train(\n\u001b[1;32m    361\u001b[0m                 \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, documents, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    926\u001b[0m         total_words, corpus_count = self.vocabulary.scan_vocab(\n\u001b[1;32m    927\u001b[0m             \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m             \u001b[0mprogress_per\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m         )\n\u001b[1;32m    930\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mscan_vocab\u001b[0;34m(self, documents, corpus_file, docvecs, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaggedLineDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m         \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scan_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         logger.info(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36m_scan_vocab\u001b[0;34m(self, documents, docvecs, progress_per, trim_rule)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdocument_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchecked_string_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m                     logger.warning(\n\u001b[1;32m   1056\u001b[0m                         \u001b[0;34m\"Each 'words' should be a list of words (usually unicode strings). \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "# Create CBOW model \n",
    "model1 = gensim.models.Doc2Vec(df_train['Tokens'], min_count = 1, size = 300, window = 5) \n",
    "\n",
    "model2 = gensim.models.Doc2Vec(df_train['Tokens'], min_count = 1, size = 300, \n",
    "                                             window = 5, sg = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between 'trump' and 'facebook' - CBOW Gram :  0.90871054\n",
      "Cosine similarity between 'trump' and 'facebook' - Skip Gram :  0.71090585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Print results \n",
    "print(\"Cosine similarity between 'trump' \" +\n",
    "          \"and 'facebook' - CBOW Gram : \", \n",
    "    model1.similarity('trump', 'facebook')) \n",
    "      \n",
    "print(\"Cosine similarity between 'trump' \" +\n",
    "            \"and 'facebook' - Skip Gram : \", \n",
    "      model2.similarity('trump', 'facebook')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30365828, -0.13708614, -0.2978775 , -0.05190181,  0.08627668,\n",
       "        0.23044613, -0.3718273 ,  0.4843164 ,  0.16885597,  0.5094671 ,\n",
       "        0.22226027,  0.33733374,  0.30097088,  0.02182713,  0.07912996,\n",
       "       -0.4947738 ,  0.3995816 ,  0.13739586,  0.33007812, -0.05742243,\n",
       "       -0.47576   , -0.28904766, -0.35722652, -0.4248053 , -0.03551352,\n",
       "       -0.01741863,  0.57888156,  0.25720105, -0.2671308 , -0.42264146,\n",
       "       -0.3533567 ,  0.46793547, -0.893341  , -0.04854772, -0.7033893 ,\n",
       "       -0.82646567,  0.24596739, -0.6107101 ,  0.25935763, -0.03448507,\n",
       "        0.07813197, -0.09595884, -1.0127698 , -0.638655  , -1.0723855 ,\n",
       "        0.70451736,  0.61105055,  0.66271955,  0.517212  ,  0.25973734,\n",
       "        0.7878838 , -0.73284537,  0.04226067,  0.48667702,  0.20541129,\n",
       "       -0.07256269, -0.5981365 ,  0.39681685,  0.08420083,  0.10966729,\n",
       "       -0.2888665 ,  0.31220788, -0.48453742,  0.07837938, -0.0934082 ,\n",
       "        0.5775672 ,  0.1575059 ,  0.40698555, -0.18017048,  0.22700903,\n",
       "       -0.17534094,  0.4085757 , -0.04484918, -0.45572296,  0.08445511,\n",
       "        0.6633689 ,  0.08781025,  0.03870269,  0.6189587 , -0.19271632,\n",
       "       -0.2582507 ,  0.6427728 ,  0.11337224,  0.9494727 ,  0.02253068,\n",
       "        0.13639234,  0.14166497,  0.21297547,  0.15234117, -0.02614545,\n",
       "        0.60077137,  0.0877528 ,  0.3082214 , -0.6386489 ,  0.1278161 ,\n",
       "       -0.00371268,  0.01271026,  0.33250913,  0.17736992,  0.27728054,\n",
       "        0.49670398, -0.34803632,  0.14269748,  0.18806292,  0.12210913,\n",
       "       -0.46371216,  0.21899988,  0.29156122,  0.46203962,  0.5474891 ,\n",
       "       -0.2825691 , -0.8061182 , -0.02238118,  1.116539  , -0.5425573 ,\n",
       "       -0.43709257,  0.7532867 , -0.9723384 , -1.0705545 , -0.12781519,\n",
       "        0.00207923,  0.41096476, -0.11659034, -0.24615426, -0.29010963,\n",
       "        0.45657417, -0.65752894,  0.10204159, -0.4260625 ,  0.75031245,\n",
       "       -0.28466392,  0.10940816,  0.05016467, -0.19911559, -0.21020964,\n",
       "       -0.31747627,  0.8084624 ,  0.7239158 ,  0.6855499 ,  0.45061767,\n",
       "        0.11339281, -0.6759301 , -0.49239308, -0.33702117, -0.5417406 ,\n",
       "       -0.19375844, -0.24648544,  0.00972147, -0.10702813, -0.05952016,\n",
       "       -0.25531083,  0.52327085,  0.04672491, -0.19803227,  0.08883203,\n",
       "        0.7483691 ,  0.22345702,  0.3154041 ,  0.5638166 ,  0.11248113,\n",
       "       -0.27559322, -1.0500478 ,  0.4889867 ,  0.7854659 , -0.12734641,\n",
       "       -0.04903129,  0.5172037 ,  0.4074352 , -0.2562368 ,  0.12470448,\n",
       "       -0.5964887 , -0.2582328 , -0.47457552, -0.33658022, -0.42370427,\n",
       "        0.57659304, -0.8390545 ,  0.12905237,  0.04941815,  0.70392233,\n",
       "       -0.09070905, -0.2913821 , -0.13853413, -0.8343309 , -0.32891324,\n",
       "        1.0591836 , -0.31726348, -1.2249236 ,  0.40714073, -0.38104257,\n",
       "       -0.5512104 ,  0.15492542,  0.39005542,  0.23975515,  1.102894  ,\n",
       "        0.70743734, -0.0892476 ,  0.52135324, -0.00456465, -0.75512695,\n",
       "        0.02267377,  0.2905266 ,  0.6735738 ,  0.277316  ,  0.75485104,\n",
       "        0.5753235 ,  0.01963024,  0.40995255,  0.4576444 ,  0.26384273,\n",
       "       -0.03958094, -0.0100059 , -0.10441095, -0.27377024, -0.5479031 ,\n",
       "        0.20747742,  0.48753604,  0.33151627,  0.4066199 , -0.286198  ,\n",
       "       -0.36997324, -0.3514886 , -0.29833388, -1.1706886 , -0.03833143,\n",
       "       -0.20238745, -0.05273012, -1.0306847 ,  1.1355824 ,  0.10863014,\n",
       "        0.10495924, -0.28493962,  0.04366107, -0.19015841,  0.70651746,\n",
       "       -0.24414635,  0.2608591 ,  0.2906269 , -0.1231119 , -0.0351934 ,\n",
       "        0.48808247,  0.19411243,  0.3520555 ,  0.07162163,  0.47525513,\n",
       "        0.2683744 ,  0.78965044,  0.35894063, -0.9436733 , -0.40026274,\n",
       "       -0.30666777, -0.76430225, -0.738105  , -0.11298915, -0.1555606 ,\n",
       "        0.41992825, -0.43883488, -0.4213005 ,  0.05918803, -0.6333056 ,\n",
       "       -0.29403687,  0.80352765,  0.24096459, -0.49264663, -0.00135754,\n",
       "       -0.09394623, -0.29380584, -0.41848862,  0.70095974,  0.21142769,\n",
       "        0.5041959 ,  0.29655042, -0.0920171 ,  0.3855458 ,  0.05853385,\n",
       "       -0.9279939 ,  0.21926874,  0.25293598, -1.0083377 , -0.3763861 ,\n",
       "        0.8385567 ,  0.41080904,  0.17427096, -0.79003394, -0.3661377 ,\n",
       "       -0.58555657,  0.5287716 , -0.3278445 ,  0.34017465,  0.27078804,\n",
       "       -0.06682698,  0.8341107 ,  0.8529902 ,  0.4623162 , -0.09119518,\n",
       "        0.5184429 , -0.19751306,  0.46832013,  0.00637078,  0.24175064],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.wv['trump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(model1.wv.vocab):\n",
    "    if i == 100:\n",
    "        break\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-1d0a552b019b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#https://www.kdnuggets.com/2018/11/multi-class-text-classification-doc2vec-logistic-regression.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "#https://www.kdnuggets.com/2018/11/multi-class-text-classification-doc2vec-logistic-regression.html\n",
    "doc.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.doc2vec.TaggedDocument"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_tagged.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29506206e8149b8ae624895babb7dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5841f778f8b4865828018112e44b44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6e6dd536ec48c19c545832ea0bdf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = df['Quote'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(np.array(padded))\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['ALBERT Tokens']\n",
    "y_train = df_train['Label']\n",
    "\n",
    "X_test = df_test['ALBERT Tokens']\n",
    "y_test = df_test['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AlbertModel' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-96d2ea965cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AlbertModel' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "model = AlbertModel.from_pretrained('albert-base-v2')\n",
    "\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# outputs = model(**X_train)\n",
    "learning_rate = 2e-5\n",
    "# we will do just 1 epoch for illustration, though multiple epochs might be better as long as we will not overfit the model\n",
    "number_of_epochs = 1\n",
    "# model initialization\n",
    "# classifier Adam recommended\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
    "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# last_hidden_states = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.3997,  1.5700,  0.3336,  ..., -0.0686,  0.2804,  0.8287],\n",
       "          [ 0.3306,  0.3647,  0.7145,  ..., -0.5266,  1.2512, -0.7155],\n",
       "          [ 1.1538,  0.6781, -1.6579,  ...,  0.6821,  0.3878,  0.4889],\n",
       "          ...,\n",
       "          [ 1.5001, -0.4411,  1.2422,  ...,  1.3102,  0.0211, -1.0564],\n",
       "          [ 0.4044, -0.0901,  1.0914,  ...,  0.4799,  0.6582, -1.0785],\n",
       "          [ 0.0455,  0.1439, -0.0616,  ..., -0.0906,  0.1141,  0.2033]]],\n",
       "        grad_fn=<NativeLayerNormBackward>),\n",
       " tensor([[ 0.4210, -0.5434,  0.7271, -0.9191,  0.6473, -0.9005,  0.5429, -0.4988,\n",
       "           0.5720, -0.9995,  0.9408,  0.4471, -0.1917, -0.9711, -0.9631, -0.4996,\n",
       "           0.4965,  0.5118,  0.9865, -0.5392, -0.8583, -0.9906,  0.9915,  0.9829,\n",
       "           0.7456, -0.5302,  0.6063, -0.9586, -0.9997, -0.5337, -1.0000,  0.5163,\n",
       "           0.5575,  0.5369,  0.5593, -0.4074,  0.5447,  0.9906, -0.5874,  0.5187,\n",
       "           0.5323, -0.9912, -0.8540,  0.4816,  0.5048,  0.5025,  0.9911, -0.9777,\n",
       "           0.6952, -0.4762, -0.4930, -0.4002, -0.5218, -0.9880,  0.0150,  0.6045,\n",
       "          -0.5614, -0.4096,  0.9999,  0.1719,  0.4423, -0.5799,  0.5456,  0.5496,\n",
       "          -0.5179,  0.5253,  0.5120,  0.9959, -0.4334,  0.9817,  0.4665,  0.5462,\n",
       "          -0.1043, -0.5992,  0.9410,  0.5802,  0.8560,  0.4975,  0.4720, -0.9925,\n",
       "           0.8159,  0.5343, -0.5573,  0.6004, -0.9708, -0.9843,  0.7708, -0.9999,\n",
       "           0.5625,  0.9666,  0.4959,  0.5485, -0.4487, -1.0000,  0.5629, -0.5661,\n",
       "          -0.9990,  0.5158,  0.5411, -0.5124,  0.9132, -0.5144,  0.4857, -0.5608,\n",
       "          -0.3920, -0.5060,  0.5094,  0.5063,  0.5195,  0.9944, -0.8588, -0.4856,\n",
       "           0.4764,  0.9826, -0.5698,  0.5832, -0.5491,  0.9228, -0.9975,  0.5857,\n",
       "           0.4849,  0.3275,  0.5167, -0.3281,  0.5163, -0.5600,  0.4692, -0.8449,\n",
       "           0.9807, -0.8199,  0.3580,  0.4315, -0.9989,  0.3295,  0.5554,  0.9910,\n",
       "          -0.4575, -0.5113, -0.5928,  0.6101,  0.9367, -0.4435,  0.5488, -0.5875,\n",
       "          -0.5116,  0.3709,  0.9295, -0.2983,  0.4345,  0.9813, -0.9209,  0.9699,\n",
       "          -0.3039, -0.8586, -0.9991, -0.0597,  0.9854, -0.8224,  0.6655, -0.4803,\n",
       "          -0.4117, -0.9439, -0.9982, -0.4949, -0.9912, -0.5281,  0.9998, -0.5351,\n",
       "           0.9993, -0.9867, -0.3785,  0.4250, -0.5244,  0.9428,  0.4925,  0.5232,\n",
       "           0.4168,  0.4628, -0.4998, -0.3952,  0.9902, -0.9996,  0.4414,  0.5016,\n",
       "           0.9888,  0.5791,  0.5023, -0.9618,  0.4663, -0.7399, -0.5158, -0.4372,\n",
       "           0.5476,  0.4948,  1.0000, -0.6292,  0.9937, -0.9875,  0.9910, -0.9993,\n",
       "          -0.5883,  0.8483,  0.8606,  0.5148,  0.5125,  0.8731, -0.7490, -0.9870,\n",
       "          -0.9997, -0.5030, -0.9963,  0.9203, -0.9836,  0.5038, -0.9991,  0.9873,\n",
       "           0.9807, -0.5441,  0.9999, -0.5261,  0.5325,  0.5220, -1.0000,  0.8078,\n",
       "           0.4175,  0.4831, -0.2078, -0.5187,  0.9176, -0.9929, -0.8662, -0.6152,\n",
       "           0.5457, -0.9998, -0.7500, -0.5805,  0.5791,  0.5537,  0.5826, -0.9998,\n",
       "           0.9996,  0.5333, -0.4494, -0.4744, -0.3976,  1.0000, -0.8057, -0.2294,\n",
       "          -0.4848,  0.9997,  0.8983,  0.4879,  0.5954, -0.4960,  0.8928, -0.4713,\n",
       "          -0.9987, -0.5667, -0.9952,  0.5283, -0.9915,  0.8843, -0.4064, -0.9981,\n",
       "          -0.5127,  0.9661,  0.9995,  0.9978,  0.5438, -0.6124,  0.4554, -0.5291,\n",
       "           0.8605, -0.3898,  0.9807, -0.9522, -0.9146,  0.6140,  0.6121,  0.4812,\n",
       "          -0.6280, -0.7226,  0.5369, -0.5248,  0.9961, -0.8673,  0.9998, -0.9319,\n",
       "          -0.9999,  0.5357, -0.5439, -0.5405,  0.9986, -0.4926, -0.9993, -0.9999,\n",
       "           0.6004,  0.9718,  0.9447, -0.9910,  0.5184, -0.5452, -0.5276,  0.9894,\n",
       "           0.4840, -0.5163, -0.4059,  0.5407,  0.4273,  0.3724, -0.9828, -0.5032,\n",
       "           0.0221, -0.9973, -0.6019, -0.5823, -0.4484, -0.8652,  0.9952,  0.9975,\n",
       "          -0.5274, -0.6358,  0.9984, -0.9978,  0.5407, -1.0000,  0.8791, -0.9995,\n",
       "          -0.9992, -0.1701, -0.8291, -0.5729, -0.5434, -0.9619,  0.5293, -0.9939,\n",
       "           0.4539, -0.5840,  0.9792,  0.9804, -0.9998, -0.4464, -0.6631,  0.5181,\n",
       "           0.5902,  0.5094,  0.2596, -0.8012,  0.5484, -0.9941,  0.5203,  0.6072,\n",
       "          -0.5265,  0.9461, -0.5546,  0.5023, -0.9674, -0.6571, -0.4998,  0.9728,\n",
       "           0.9974, -0.6704, -0.4482,  0.5587, -0.8370,  0.9511, -0.8521,  0.9458,\n",
       "          -0.9989, -0.5432, -0.9892,  0.9997,  0.9718,  0.1258, -0.5306, -0.8302,\n",
       "          -0.9978,  0.5399, -0.5480, -0.4312, -0.5414,  0.9728,  0.4807,  0.8907,\n",
       "          -0.7789, -0.1091,  0.4736,  0.1994, -0.9850,  0.9897, -0.4486, -0.5212,\n",
       "           0.5505,  1.0000, -0.5767,  0.5629, -0.9641, -0.9952, -0.5144,  0.4639,\n",
       "           0.9879, -0.4969, -0.8273,  0.9660,  0.9790, -0.9984,  0.5206,  0.9949,\n",
       "           0.9475,  0.5503,  0.6140,  0.8900,  0.7951,  0.5212,  0.9901, -0.5013,\n",
       "           0.9998, -0.9924, -0.9996,  0.9970, -0.5224,  0.9967, -0.7967,  0.4161,\n",
       "          -0.1884,  0.5780, -0.5985, -0.5452,  0.5077,  0.4001,  0.6284,  0.9980,\n",
       "           0.4899, -0.9952, -0.9999,  0.8665,  0.5873,  0.6209, -0.4754,  0.9352,\n",
       "          -0.4969, -0.2195, -0.6436, -0.5853,  0.5363, -0.9999,  1.0000, -0.9939,\n",
       "           0.9969, -0.5397,  0.7483,  0.8474,  0.9623, -0.5601, -1.0000, -0.6001,\n",
       "          -0.9986,  0.5340, -0.4916, -0.9281, -0.4791,  0.9572, -0.4706,  0.9698,\n",
       "           0.5327, -0.5862, -0.9824,  1.0000, -0.9599, -0.9996,  0.5040,  0.5384,\n",
       "           0.2574,  0.5472,  0.4830,  0.4871, -0.7692, -0.4650,  0.9861, -0.9848,\n",
       "           0.8120, -0.9306,  0.9370, -0.6103, -0.3447,  0.9307,  0.9994,  0.9978,\n",
       "          -0.3793, -1.0000, -0.9938, -0.9987, -0.9936,  0.4620, -0.8721,  0.8313,\n",
       "          -0.5636, -0.4761,  0.9763,  0.9151, -0.4972, -0.4994, -0.9685, -0.8029,\n",
       "          -0.3977, -0.9450,  0.5183, -0.9968, -0.7668, -0.9669, -0.9786, -0.4693,\n",
       "          -0.9986,  0.4883, -0.9999,  0.3214, -0.5459,  0.1489, -0.4473,  0.5056,\n",
       "           0.5446, -0.4668,  0.4982,  0.9892, -0.5627,  1.0000,  0.9999,  0.9015,\n",
       "           0.5120, -0.8579, -0.5660,  0.9995, -0.1473, -0.9736,  0.9165, -0.8402,\n",
       "           0.9379, -0.9770,  0.9936, -0.9485, -0.9724, -0.9982, -0.4288, -0.9997,\n",
       "          -0.9995, -0.9998,  0.5450,  0.9799, -0.9895,  0.9999,  0.5638, -0.8712,\n",
       "           0.9987,  0.5540, -0.8249,  0.4360, -0.5759,  1.0000, -0.4691,  0.9734,\n",
       "          -0.4816, -0.9940,  0.9764,  0.8089, -0.5404, -0.4220, -0.9696, -0.6566,\n",
       "           0.8398, -0.5000,  0.5988,  0.9999, -0.9242,  0.5128, -0.5264,  0.5278,\n",
       "          -0.9467,  0.4628, -0.5471, -0.1702, -0.9898, -0.9969,  0.9996,  0.5281,\n",
       "           0.5010,  0.5000,  0.6324, -0.3229,  0.9998, -0.9998, -0.5153,  0.4648,\n",
       "          -0.7673,  0.9637, -0.4484, -0.6206,  0.5036,  0.9903, -0.4603,  0.9983,\n",
       "           0.0191,  0.5208,  0.4760,  0.4837,  0.4561,  0.9993,  0.5214, -0.9870,\n",
       "          -0.4332, -0.4943, -0.4646,  0.9996,  0.9989, -0.9004, -0.4284, -0.5150,\n",
       "          -0.9960,  0.9964,  0.9534,  0.9972,  0.9990,  0.6625, -0.4381, -0.9812,\n",
       "           0.9987,  0.8982, -0.5809,  0.1941,  0.6526, -0.4842,  0.8758,  0.9870,\n",
       "          -0.9720,  0.2120,  0.5801,  0.9996,  0.9979, -0.5340,  0.9515, -1.0000,\n",
       "          -0.5587,  0.9806, -0.9629,  0.5611,  0.9908, -1.0000, -0.5280, -0.5096,\n",
       "           0.8218,  0.9917,  0.5048,  0.4847, -0.4399, -0.5408,  0.9904,  0.4469,\n",
       "          -0.5984,  0.9977, -0.5633, -0.4555,  0.5179,  0.5312,  0.9999,  0.9566,\n",
       "          -0.9878, -0.4622,  0.5494, -0.5263,  0.9334, -1.0000, -0.4901,  0.3560,\n",
       "          -0.5465,  0.4571,  0.8961,  0.5983, -0.5828, -0.9988,  0.5158,  0.7385,\n",
       "           0.5030,  0.9960,  0.5150, -0.4220,  0.2893,  0.9180, -0.4287,  0.7887,\n",
       "          -0.9976,  0.4030, -0.7712,  0.4973, -0.4949, -0.9898, -0.5825,  0.5870,\n",
       "           0.9802,  0.5364,  0.5452,  0.3904, -0.5534,  0.5692,  0.5118,  0.4368,\n",
       "          -0.4600, -0.5287, -0.5252, -0.9995,  0.6493,  0.4779,  0.5272,  0.5819,\n",
       "          -0.3902, -0.4604,  0.5597, -0.5466,  0.6364, -0.3192, -1.0000, -0.5740,\n",
       "          -0.7581, -0.4839,  0.5710, -0.6105,  0.6137, -0.8194, -0.9999,  0.5065,\n",
       "           0.4850, -0.9597,  0.4882, -0.9757,  0.5086,  0.9999,  1.0000, -0.9883,\n",
       "           0.5399, -0.9974, -0.5105, -0.4614, -1.0000,  0.4562,  0.9999,  0.3122,\n",
       "           0.4675, -0.9840, -0.7734,  0.9998, -0.9692, -0.5096,  0.5919, -0.4768,\n",
       "          -0.9995,  0.8067,  0.5788,  0.5774,  0.5846, -0.9930, -0.6216,  0.7071,\n",
       "          -0.9927,  0.4395,  0.9990, -0.5195,  0.4382, -0.3884, -0.9979,  0.5893]],\n",
       "        grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/kelkin/.local/lib/python3.7/site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.16.4)\n",
      "Requirement already satisfied: requests in /home/kelkin/.local/lib/python3.7/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/kelkin/.local/lib/python3.7/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kelkin/.local/lib/python3.7/site-packages (from transformers) (2020.7.14)\n",
      "Requirement already satisfied: sacremoses in /home/kelkin/.local/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /home/kelkin/.local/lib/python3.7/site-packages (from transformers) (0.8.1rc1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.32.2)\n",
      "Requirement already satisfied: filelock in /home/kelkin/.local/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (19.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.3)\n",
      "Requirement already satisfied: six in /home/kelkin/.local/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
